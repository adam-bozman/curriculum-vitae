position_data %>% print_section('education')
knitr::opts_chunk$set(
results='asis',
echo = FALSE
)
library(glue)
library(tidyverse)
# ======================================================================
# These variables determine how the the data is loaded and how the exports are
# done.
# Is data stored in google sheets? If no data will be gather from the csvs/
# folder in project
using_googlesheets <- TRUE
# Just the copied URL from the sheet
positions_sheet_loc <- "https://docs.google.com/spreadsheets/d/12AmefhEuBoa0XrE_HuAGE4WOpjTIaLa_lIOwkKJKWy4/edit?usp=sharing"
# Is this sheet available for anyone to read? If you're using a private sheet
# set this to false and go to gather_data.R and run the data loading manually
# once to cache authentication
sheet_is_publicly_readable <- TRUE
# Is the goal of this knit to build a document that is exported to PDF? If so
# set this to true to have links turned into footnotes at the end of the
# document
PDF_EXPORT <- FALSE
CV_PDF_LOC <- "github.com/dcossyleon/cv/raw/master/cv.pdf"
CV_HTML_LOC <- "dcossyleon.github.io/cv/"
# A global (gasp) variable that holds all the links that were inserted for
# placement at the end
links <- c()
# ======================================================================
# Now we source two external scripts. One contains functions for building the
# text output and the other loads up our data from either googlesheets or csvs
# Functions for building sections from CSV data
source('parsing_functions.R')
# Load data for CV/Resume
source('gather_data.R')
knitr::opts_chunk$set(
results='asis',
echo = FALSE
)
library(glue)
library(tidyverse)
# ======================================================================
# These variables determine how the the data is loaded and how the exports are
# done.
# Is data stored in google sheets? If no data will be gather from the csvs/
# folder in project
using_googlesheets <- TRUE
# Just the copied URL from the sheet
positions_sheet_loc <- "https://docs.google.com/spreadsheets/d/12AmefhEuBoa0XrE_HuAGE4WOpjTIaLa_lIOwkKJKWy4/edit?usp=sharing"
# Is this sheet available for anyone to read? If you're using a private sheet
# set this to false and go to gather_data.R and run the data loading manually
# once to cache authentication
sheet_is_publicly_readable <- TRUE
# Is the goal of this knit to build a document that is exported to PDF? If so
# set this to true to have links turned into footnotes at the end of the
# document
PDF_EXPORT <- FALSE
CV_PDF_LOC <- "github.com/dcossyleon/cv/raw/master/cv.pdf"
CV_HTML_LOC <- "dcossyleon.github.io/cv/"
# A global (gasp) variable that holds all the links that were inserted for
# placement at the end
links <- c()
# ======================================================================
# Now we source two external scripts. One contains functions for building the
# text output and the other loads up our data from either googlesheets or csvs
# Functions for building sections from CSV data
source('parsing_functions.R')
# Load data for CV/Resume
source('gather_data.R')
# When in export mode the little dots are unaligned, so fix that.
if(PDF_EXPORT){
cat("
<style>
:root{
--decorator-outer-offset-left: -6.5px;
}
</style>")
}
print_text_block(text_blocks, 'intro')
# When in export mode the little dots are unaligned, so fix that.
if(PDF_EXPORT){
glue("View this CV online with links at _{CV_HTML_LOC}_")
} else {
glue("[<i class='fas fa-download'></i> Download CV as a PDF]({CV_PDF_LOC})")
}
contact_info %>%
glue_data("- <i class='fa fa-{icon}'></i> {contact}")
print_section(position_data, 'experience')
print_section(position_data, 'education')
install.packages('devtools')
install.packages('datadrivencv')
install.packages('remotes')
devtools::install_github("nstrayer/datadrivencv")
remotes::install_github('mitchelloharawild/icons@v0.1.0')
devtools::install_github("nstrayer/datadrivencv")
library(datadrivencv)
datadrivencv::use_datadriven_cv()
datadrivencv::use_datadriven_cv()
datadrivencv::use_datadriven_cv(
full_name = 'Adam Bozman',
)
datadrivencv::use_datadriven_cv(
full_name = 'Adam Bozman',
data_location = 'https://docs.google.com/spreadsheets/d/12AmefhEuBoa0XrE_HuAGE4WOpjTIaLa_lIOwkKJKWy4/edit?usp=sharing',
pdf_location = 'https://github.com/adam-bozman/curriculum-vitae/cv.pdf',
html_location = 'https://www.adambozman.com/about/cv.html/',
source_location = 'https://github.com/adam-bozman/curriculum-vitae'
)
# This tells google sheets to not try and authenticate. Note that this will only
# work if your sheet has sharing set to "anyone with link can view"
googlesheets4::gs4_deauth()
# Convert to PDF using Pagedown
pagedown::chrome_print(input = tmp_html_cv_loc,
output = "cv.pdf")
cv$entries_data  <- read_gsheet(sheet_id = "positions")
datadrivencv::use_datadriven_cv(
full_name = 'Adam N. Bozman'
)
datadrivencv::use_datadriven_cv(
full_name = 'Adam N. Bozman'
)
# Want to go old-school with csvs?
cv$entries_data <- readr::read_csv(paste0(data_location, "entries.csv"), skip = 1)
install.packages('pdf_export')
install.packages('glue')
install.packages("glue")
library(glue)
# Convert to PDF using Pagedown
pagedown::chrome_print(input = tmp_html_cv_loc,
output = "cv.pdf")
# Knit the HTML version
rmarkdown::render("cv.rmd",
params = list(pdf_mode = FALSE),
output_file = "cv.html")
CV_PDF_LOC
# Knit the PDF version to temporary html location
tmp_html_cv_loc <- fs::file_temp(ext = ".html")
rmarkdown::render("cv.rmd",
params = list(pdf_mode = TRUE),
output_file = tmp_html_cv_loc)
# Convert to PDF using Pagedown
pagedown::chrome_print(input = tmp_html_cv_loc,
output = "cv.pdf")
knit_with_parameters("C:/Users/adam.bozman/OneDrive - Washington State University (email.wsu.edu)/R Workshop/rsites/curriculum-vitae/cv.rmd")
knit_with_parameters("C:/Users/adam.bozman/OneDrive - Washington State University (email.wsu.edu)/R Workshop/rsites/curriculum-vitae/cv.rmd")
#' @param data_location Path of the spreadsheets holding all your data. This can be
#'   either a URL to a google sheet with multiple sheets containing the four
#'   data types or a path to a folder containing four `.csv`s with the neccesary
#'   data.
#' @param source_location Where is the code to build your CV hosted?
#' @param pdf_mode Is the output being rendered into a pdf? Aka do links need
#'   to be stripped?
#' @param sheet_is_publicly_readable If you're using google sheets for data,
#'   is the sheet publicly available? (Makes authorization easier.)
#' @return A new `CV_Printer` object.
create_CV_object <-  function(data_location,
pdf_mode = TRUE,
sheet_is_publicly_readable = TRUE) {
cv <- list(
pdf_mode = pdf_mode,
links = c()
)
is_google_sheets_location <- stringr::str_detect(data_location, "docs\\.google\\.com")
if(is_google_sheets_location){
if(sheet_is_publicly_readable){
# This tells google sheets to not try and authenticate. Note that this will only
# work if your sheet has sharing set to "anyone with link can view"
googlesheets4::gs4_deauth()
} else {
# My info is in a public sheet so there's no need to do authentication but if you want
# to use a private sheet, then this is the way you need to do it.
# designate project-specific cache so we can render Rmd without problems
options(gargle_oauth_cache = ".secrets")
}
read_gsheet <- function(sheet_id){
googlesheets4::read_sheet(data_location, sheet = sheet_id, skip = 1, col_types = "c")
}
cv$entries_data  <- read_gsheet(sheet_id = "positions")
cv$skills        <- read_gsheet(sheet_id = "language_skills")
cv$text_blocks   <- read_gsheet(sheet_id = "text_blocks")
cv$contact_info  <- read_gsheet(sheet_id = "contact_info")
} else {
# Want to go old-school with csvs?
cv$entries_data <- readr::read_csv(paste0(data_location, "entries.csv"), skip = 1)
cv$skills       <- readr::read_csv(paste0(data_location, "language_skills.csv"), skip = 1)
cv$text_blocks  <- readr::read_csv(paste0(data_location, "text_blocks.csv"), skip = 1)
cv$contact_info <- readr::read_csv(paste0(data_location, "contact_info.csv"), skip = 1)
}
extract_year <- function(dates){
date_year <- stringr::str_extract(dates, "(20|19)[0-9]{2}")
date_year[is.na(date_year)] <- lubridate::year(lubridate::ymd(Sys.Date())) + 10
date_year
}
parse_dates <- function(dates){
date_month <- stringr::str_extract(dates, "(\\w+|\\d+)(?=(\\s|\\/|-)(20|19)[0-9]{2})")
date_month[is.na(date_month)] <- "1"
paste("1", date_month, extract_year(dates), sep = "-") %>%
lubridate::dmy()
}
# Clean up entries dataframe to format we need it for printing
cv$entries_data %<>%
tidyr::unite(
tidyr::starts_with('description'),
col = "description_bullets",
sep = "\n- ",
na.rm = TRUE
) %>%
dplyr::mutate(
description_bullets = ifelse(description_bullets != "", paste0("- ", description_bullets), ""),
start = ifelse(start == "NULL", NA, start),
end = ifelse(end == "NULL", NA, end),
start_year = extract_year(start),
end_year = extract_year(end),
no_start = is.na(start),
has_start = !no_start,
no_end = is.na(end),
has_end = !no_end,
timeline = dplyr::case_when(
no_start  & no_end  ~ "N/A",
no_start  & has_end ~ as.character(end),
has_start & no_end  ~ paste("Current", "-", start),
TRUE                ~ paste(end, "-", start)
)
) %>%
dplyr::arrange(desc(parse_dates(end))) %>%
dplyr::mutate_all(~ ifelse(is.na(.), 'N/A', .))
cv
}
# Remove links from a text block and add to internal list
sanitize_links <- function(cv, text){
if(cv$pdf_mode){
link_titles <- stringr::str_extract_all(text, '(?<=\\[).+?(?=\\])')[[1]]
link_destinations <- stringr::str_extract_all(text, '(?<=\\().+?(?=\\))')[[1]]
n_links <- length(cv$links)
n_new_links <- length(link_titles)
if(n_new_links > 0){
# add links to links array
cv$links <- c(cv$links, link_destinations)
# Build map of link destination to superscript
link_superscript_mappings <- purrr::set_names(
paste0("<sup>", (1:n_new_links) + n_links, "</sup>"),
paste0("(", link_destinations, ")")
)
# Replace the link destination and remove square brackets for title
text <- text %>%
stringr::str_replace_all(stringr::fixed(link_superscript_mappings)) %>%
stringr::str_replace_all('\\[(.+?)\\]', "\\1")
}
}
list(cv = cv, text = text)
}
